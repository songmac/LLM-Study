
import streamlit as st 
from utils import print_messages, get_session_history, StreamHandler
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
from dotenv import load_dotenv
import os
load_dotenv()
api_key = os.environ["OPENAI_API_KEY"]

st.set_page_config(page_title="clone ChatGPT", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ clone ChatGPT")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì±„íŒ… ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state["store"] = dict()

# ì„¸ì…˜ ID ì§€ì •í•˜ëŠ” ì‚¬ì´ë“œë°” ë§Œë“¤ê¸°
with st.sidebar:
    session_id = st.text_input("Session ID", value = "abc123")
    # ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™” í•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€í•˜ê¸°
    clear_btn = st.button("ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state["messages"] = []
        # st.session_state["store"] = dict() # ëŒ€í™” ê¸°ë¡ ì €ì¥í•œ ê²ƒ ê¹Œì§€ ì´ˆê¸°í™” í•˜ë ¤ë©´ ì¶”ê°€í•˜ë©´ ë¨
        st.rerun()

print_messages()  # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥

user_input = st.chat_input("ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
if user_input:
    # ì‚¬ìš©ìì˜ ì…ë ¥ ì €ì¥
    st.chat_message("user").write(f"{user_input}")
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))

    # 5) AIì˜ ë‹µë³€ ì¶œë ¥
    with st.chat_message("assistant"):
        stream_handler = StreamHandler(st.empty())

        # LLMì„ ì‚¬ìš©í•˜ì—¬ AIì˜ ë‹µë³€ì„ ìƒì„±
        # 1) ëª¨ë¸ ìƒì„±
        llm = ChatOpenAI(
            temperature=0, 
            model_name='gpt-4-turbo', 
            api_key=api_key, 
            streaming=True, 
            callbacks=[stream_handler]
        )

        # 2) í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "ì§ˆë¬¸ì— ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."),
                MessagesPlaceholder(variable_name="history"),  # ëŒ€í™” ê¸°ë¡ ì‚¬ìš©
                ("human", "{question}")  # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
            ]
        )

        chain = prompt | llm 

        # 3) ë©”ëª¨ë¦¬ ì ìš©í•œ ì²´ì¸ ìƒì„±
        chain_with_memory = RunnableWithMessageHistory(
            chain,  # ì‹¤í–‰í•  Runnable ê°ì²´
            get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
            input_messages_key="question",  # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
            history_messages_key="history",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤
        )

        # 4) AI ì‘ë‹µ ìƒì„±
        response = chain_with_memory.invoke(
            {"question": user_input},
            config={"configurable": {"session_id": session_id}}
        )

        # 6) í† í° í•˜ë‚˜í•˜ë‚˜ ë‹¹ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥
        st.session_state["messages"].append(ChatMessage(role="assistant", content=response.content))
