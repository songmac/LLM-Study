{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith API Key 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langsmith로 프로젝트 추적 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Memory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화 버퍼 메모리, LECL Chain에 메모리 추가,  RunnableWithMessageHistory에 ChatMessageHistory추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 메모리는 메시지를 저장한 다음 변수에 메시지를 추출할 수 있게 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selena\\AppData\\Local\\Temp\\ipykernel_12000\\3070049519.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    inputs={ # 사용자의 입력 저장\n",
    "        \"human\": \"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    "    },\n",
    "    outputs={ # AI의 출력을 저장\n",
    "        \"ai\": \"안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_context(inputs, outputs) 메서드를 사용하면 대화 기록이 history 키에 저장됩니다.\n",
    "\n",
    "이후 load_memory_variables({}) 메서드를 사용하여 저장된 대화 기록을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\\nAI: 안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'history' 키에 저장된 대화 기록을 확인합니다.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3개의 대화를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"인증번호를 입력했습니다. 계좌 개설은 이제 어떻게 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"본인 인증이 완료되었습니다. 이제 원하시는 계좌 종류를 선택하고 필요한 정보를 입력해 주세요. 예금 종류, 통화 종류 등을 선택할 수 있습니다.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\n",
      "AI: 안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\n",
      "Human: 네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\n",
      "AI: 감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\n",
      "Human: 사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\n",
      "AI: 업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\n",
      "Human: 인증번호를 입력했습니다. 계좌 개설은 이제 어떻게 하나요?\n",
      "AI: 본인 인증이 완료되었습니다. 이제 원하시는 계좌 종류를 선택하고 필요한 정보를 입력해 주세요. 예금 종류, 통화 종류 등을 선택할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# history에 저장된 대화 기록을 확인합니다.\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가로 2개의 대화를 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"정보를 모두 입력했습니다. 다음 단계는 무엇인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"입력해 주신 정보를 확인했습니다. 계좌 개설 절차가 거의 끝났습니다. 마지막으로 이용 약관에 동의해 주시고, 계좌 개설을 최종 확인해 주세요.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"모든 절차를 완료했습니다. 계좌가 개설된 건가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"네, 계좌 개설이 완료되었습니다. 고객님의 계좌 번호와 관련 정보는 등록하신 이메일로 발송되었습니다. 추가적인 도움이 필요하시면 언제든지 문의해 주세요. 감사합니다!\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\n",
      "AI: 안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\n",
      "Human: 네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\n",
      "AI: 감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\n",
      "Human: 사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\n",
      "AI: 업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\n",
      "Human: 인증번호를 입력했습니다. 계좌 개설은 이제 어떻게 하나요?\n",
      "AI: 본인 인증이 완료되었습니다. 이제 원하시는 계좌 종류를 선택하고 필요한 정보를 입력해 주세요. 예금 종류, 통화 종류 등을 선택할 수 있습니다.\n",
      "Human: 정보를 모두 입력했습니다. 다음 단계는 무엇인가요?\n",
      "AI: 입력해 주신 정보를 확인했습니다. 계좌 개설 절차가 거의 끝났습니다. 마지막으로 이용 약관에 동의해 주시고, 계좌 개설을 최종 확인해 주세요.\n",
      "Human: 모든 절차를 완료했습니다. 계좌가 개설된 건가요?\n",
      "AI: 네, 계좌 개설이 완료되었습니다. 고객님의 계좌 번호와 관련 정보는 등록하신 이메일로 발송되었습니다. 추가적인 도움이 필요하시면 언제든지 문의해 주세요. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "# history에 저장된 대화 기록을 확인합니다.\n",
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return_messages=True 로 설정하면 HumanMessage 와 AIMessage 객체를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# history에 저장된 대화 기록을 확인합니다.\n",
    "memory.load_memory_variables({})[\"history\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain 에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곧 지원 종료 예정인 코드이므로 RunnableWithMessageHistory 로 변경할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selena\\AppData\\Local\\Temp\\ipykernel_12000\\1451290617.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 비대면으로 은행 계좌를 개설하려면 먼저 해당 은행의 공식 웹사이트나 앱을 방문하셔야 합니다. 대부분의 은행은 온라인으로 계좌를 개설할 수 있는 서비스를 제공하고 있습니다. 웹사이트나 앱을 통해 개설 절차를 따라가시면 됩니다. 개인 정보와 신분증 사진 등을 제출해야 할 수도 있습니다. 개설이 완료되면 은행에서 계좌 정보를 제공해줄 것입니다. 도움이 되셨나요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# LLM 모델을 생성합니다.\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# ConversationChain을 생성합니다.\n",
    "conversation = ConversationChain( \n",
    "    # ConversationBufferMemory를 사용합니다.\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    ")\n",
    "\n",
    "# 대화를 시작합니다.\n",
    "response = conversation.predict(\n",
    "    input=\"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전의 대화 기록을 기억하고 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 해당 은행의 공식 웹사이트나 앱을 방문\n",
      "2. 온라인으로 계좌 개설 서비스 이용\n",
      "3. 개인 정보와 신분증 사진 제출\n",
      "4. 은행에서 계좌 정보 제공\n"
     ]
    }
   ],
   "source": [
    "# 이전 대화내용을 불렛포인트로 정리해 달라는 요청을 보냅니다.\n",
    "response = conversation.predict(\n",
    "    input=\"이전 답변을 불렛포인트 형식으로 정리하여 알려주세요.\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터 저장소 검색 메모리 (VectorStoreRetrieverMemory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VectorStoreRetrieverMemory 는 벡터 스토어에 메모리를 저장하고 호출될 때마다 가장 '눈에 띄는' 상위 K개의 문서를 쿼리합니다.\n",
    "\n",
    "이는 대화내용의 순서를 명시적으로 추적하지 않는다는 점 에서 다른 대부분의 메모리 클래스와 다릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, 벡터 스토어를 초기화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 임베딩 모델을 정의합니다.\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Vector Store 를 초기화 합니다.\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 사용에서는 k를 더 높은 값으로 설정하지만, 여기서는 k=1 을 사용하여 다음과 같이 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selena\\AppData\\Local\\Temp\\ipykernel_12000\\3727791268.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=retriever)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# 벡터 조회가 여전히 의미적으로 관련성 있는 정보를 반환한다는 것을 보여주기 위해서입니다.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# 임의의 대화를 저장합니다.\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 오늘 면접에 참석해주셔서 감사합니다. 자기소개 부탁드립니다.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요. 저는 컴퓨터 과학을 전공한 신입 개발자입니다. 대학에서는 주로 자바와 파이썬을 사용했으며, 최근에는 웹 개발 프로젝트에 참여하여 실제 사용자를 위한 서비스를 개발하는 경험을 했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"프로젝트에서 어떤 역할을 맡았나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"제가 맡은 역할은 백엔드 개발자였습니다. 사용자 데이터 처리와 서버 로직 개발을 담당했으며, RESTful API를 구현하여 프론트엔드와의 통신을 담당했습니다. 또한, 데이터베이스 설계에도 참여했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"팀 프로젝트에서 어려움을 겪었던 경험이 있다면 어떻게 해결했나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"프로젝트 초기에 의사소통 문제로 몇 가지 어려움이 있었습니다. 이를 해결하기 위해 저희 팀은 정기적인 미팅을 갖고 각자의 진행 상황을 공유했습니다. 또한, 문제가 발생했을 때는 적극적으로 의견을 나누고, 합리적인 해결책을 찾기 위해 노력했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"개발자로서 자신의 강점은 무엇이라고 생각하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"제 강점은 빠른 학습 능력과 문제 해결 능력입니다. 새로운 기술이나 도구를 빠르게 습득할 수 있으며, 복잡한 문제에 직면했을 때 창의적인 해결책을 제시할 수 있습니다. 또한, 팀워크를 중시하며 동료들과 협력하는 것을 중요하게 생각합니다.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음의 질문을 했을 때 Vector Store 로 부터 1개(k=1 이기 때문)의 가장 관련성 높은 대화를 반환합니다.\n",
    "\n",
    "질문: \"면접자 전공은 무엇인가요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 안녕하세요, 오늘 면접에 참석해주셔서 감사합니다. 자기소개 부탁드립니다.\n",
      "ai: 안녕하세요. 저는 컴퓨터 과학을 전공한 신입 개발자입니다. 대학에서는 주로 자바와 파이썬을 사용했으며, 최근에는 웹 개발 프로젝트에 참여하여 실제 사용자를 위한 서비스를 개발하는 경험을 했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 메모리에 질문을 통해 가장 연관성 높은 1개 대화를 추출합니다.\n",
    "print(memory.load_memory_variables({\"prompt\": \"면접자 전공은 무엇인가요?\"})[\"history\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 다른 질문을 통해 가장 연관성 높은 1개 대화를 추출합니다.\n",
    "\n",
    "질문: \"면접자가 프로젝트에서 맡은 역할은 무엇인가요?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 프로젝트에서 어떤 역할을 맡았나요?\n",
      "ai: 제가 맡은 역할은 백엔드 개발자였습니다. 사용자 데이터 처리와 서버 로직 개발을 담당했으며, RESTful API를 구현하여 프론트엔드와의 통신을 담당했습니다. 또한, 데이터베이스 설계에도 참여했습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    memory.load_memory_variables(\n",
    "        {\"human\": \"면접자가 프로젝트에서 맡은 역할은 무엇인가요?\"}\n",
    "    )[\"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCEL Chain 에 메모리 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의의 체인에 메모리를 추가하는 방법을 보여줍니다. 현재 메모리 클래스를 사용할 수 있지만 수동으로 연결해야 합니다.\n",
    "\n",
    "conversation 대화목록을 나중에 추가하고자 할 때 MessagesPlaceholder 를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ChatOpenAI 모델을 초기화합니다.\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 대화형 프롬프트를 생성합니다. 이 프롬프트는 시스템 메시지, 이전 대화 내역, 그리고 사용자 입력을 포함합니다.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화내용을 저장할 메모리인 ConversationBufferMemory 생성하고 return_messages 매개변수를 True로 설정하여, 생성된 인스턴스가 메시지를 반환하도록 합니다.\n",
    "\n",
    "memory_key 설정: 추후 Chain 의 prompt 안에 대입될 key 입니다. 변경하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 버퍼 메모리를 생성하고, 메시지 반환 기능을 활성화합니다.\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 대화기록을 확인합니다. 아직 저장하지 않았으므로, 대화기록은 비어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # 메모리 변수를 빈 딕셔너리로 초기화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnablePassthrough.assign을 사용하여 chat_history 변수에 memory.load_memory_variables 함수의 결과를 할당하고, 이 결과에서 chat_history 키에 해당하는 값을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables)\n",
    "    | itemgetter(\"chat_history\")  # memory_key 와 동일하게 입력합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runnable 에 첫 번째 대화를 시작합니다.\n",
    "\n",
    "input: 사용자 입력 대화가 전달됩니다. chat_history: 대화 기록이 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'chat_history': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runnable.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are a helpful chatbot\"),\n",
    "#         MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#         (\"human\", \"{input}\"),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "만나서 반가워요, 셀레나님! 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 입력에 대한 응답을 생성합니다.\n",
    "response = chain.invoke({\"input\": \"만나서 반갑습니다. 제 이름은 셀레나입니다.\"})\n",
    "print(response.content)  # 생성된 응답을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory.save_context 함수는 입력 데이터(inputs)와 응답 내용(response.content)을 메모리에 저장하는 역할을 합니다. \n",
    "\n",
    "이는 AI 모델의 학습 과정에서 현재 상태를 기록하거나, 사용자의 요청과 시스템의 응답을 추적하는 데 사용될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='만나서 반갑습니다. 제 이름은 테디입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='만나서 반가워요, 셀레나님! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='만나서 반갑습니다. 제 이름은 셀레나입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='만나서 반가워요, 셀레나님! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='만나서 반갑습니다. 제 이름은 셀레나입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='만나서 반가워요, 셀레나님! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='만나서 반갑습니다. 제 이름은 셀레나입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='만나서 반가워요, 셀레나님! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력된 데이터와 응답 내용을 메모리에 저장합니다.\n",
    "memory.save_context(\n",
    "    {\"human\": \"만나서 반갑습니다. 제 이름은 셀레나입니다.\"}, {\"ai\": response.content}\n",
    ")\n",
    "\n",
    "# 저장된 대화기록을 출력합니다.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이름을 기억하고 있는지 추가 질의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 당신의 이름은 셀레나입니다. 어떤 도움이 필요하신가요?\n"
     ]
    }
   ],
   "source": [
    "# 이름을 기억하고 있는지 추가 질의합니다.\n",
    "response = chain.invoke({\"input\": \"제 이름이 무엇이었는지 기억하세요?\"})\n",
    "# 답변을 출력합니다.\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableWithMessageHistory에 ChatMessageHistory추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wikidocs.net/235581\n",
    "\n",
    "RunnableWithMessageHistory를 활용하여 특정 유형의 작업(체인)에 메시지 기록을 추가하는 것은 프로그래밍에서 상당히 유용한 기능입니다.\n",
    "\n",
    "이 기능은 특히 대화형 애플리케이션 또는 복잡한 데이터 처리 작업을 구현할 때 이전 메시지의 맥락을 유지해야 할 필요가 있을 때 중요합니다.\n",
    "\n",
    "메시지 기록을 관리함으로써, 개발자는 애플리케이션의 흐름을 더 잘 제어하고, 사용자의 이전 요청에 따라 적절하게 응답할 수 있습니다.\n",
    "\n",
    "\n",
    "정리하자면, \n",
    "\n",
    "RunnableWithMessageHistory는 애플리케이션의 상태를 유지하고, 사용자 경험을 향상시키며, 더 정교한 응답 메커니즘을 구현할 수 있게 해주는 강력한 도구입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### 이전 대화내용을 기억하는 multi-turn Chain -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# 프롬프트 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 Question-Answering 챗봇입니다. 주어진 질문에 대한 답변을 제공해주세요.\",\n",
    "        ),\n",
    "        # 대화기록용 key 인 chat_history 는 가급적 변경 없이 사용하세요!\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"#Question:\\n{question}\"),  # 사용자 입력을 변수로 사용\n",
    "    ]\n",
    ")\n",
    "\n",
    "# llm 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# 일반 Chain 생성\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화를 기록하는 체인 생성(chain_with_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 기록을 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[대화 세션ID]: {session_ids}\")\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,  # 세션 기록을 가져오는 함수\n",
    "    input_messages_key=\"question\",  # 사용자의 질문이 템플릿 변수에 들어갈 key\n",
    "    history_messages_key=\"chat_history\",  # 기록 메시지의 키\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 질문 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 셀레나! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"나의 이름은 셀레나입니다.\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이어서 질문 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 셀레나입니다.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"내 이름이 뭐라고?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 session_id가 다른 경우 새로운 세션이 생성되는 경우입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 당신의 이름은 알 수 없습니다.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"내 이름이 뭐라고?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc1234\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableWithMessageHistory 를 이용해 휘발성, 영구 메모리 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메시지 기록을 관리하는 방법을 선택할 때는 애플리케이션의 요구사항, 예상되는 트래픽 양, 메시지 데이터의 중요성 및 보존 기간 등을 고려해야 합니다. \n",
    "\n",
    "인메모리 방식은 구현이 간단하고 빠르지만, 데이터의 영구성이 요구되는 경우 Redis와 같은 영구적인 저장소를 사용하는 것이 더 적합할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnable 객체와 BaseChatMessageHistory 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runnable: 주로 Retriever, Chain 과 같이 BaseChatMessageHistory 와 상호작용하는 runnable 객체입니다.\n",
    "\n",
    "BaseChatMessageHistory의 인스턴스를 반환하는 호출 가능한 객체(callable): 메시지 기록을 관리하기 위한 객체입니다. 이 객체는 메시지 기록을 저장, 검색, 업데이트하는 데 사용됩니다. 메시지 기록은 대화의 맥락을 유지하고, 사용자의 이전 입력에 기반한 응답을 생성하는 데 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 {ability} 에 능숙한 어시스턴트입니다. 20자 이내로 응답하세요\",\n",
    "        ),\n",
    "        # 대화 기록을 변수로 사용, history 가 MessageHistory 의 key 가 됨\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # 사용자 입력을 변수로 사용\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model  # 프롬프트와 모델을 연결하여 runnable 객체 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 휘발성 대화기록 : 인메모리 ChatMessageHistory 사용하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방법은 메모리 내에서 메시지 기록을 관리합니다. 주로 개발 단계나 간단한 애플리케이션에서 사용됩니다. \n",
    "\n",
    "인메모리 방식은 빠른 접근 속도를 제공하지만, 애플리케이션을 재시작할 때 메시지 기록이 사라지는 단점이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}  # 세션 기록을 저장할 딕셔너리\n",
    "\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory 객체 생성\n",
    "        runnable,  # 실행할 Runnable 객체\n",
    "        get_session_history,  # 세션 기록을 가져오는 함수\n",
    "        input_messages_key=\"input\",  # 입력 메시지의 키\n",
    "        history_messages_key=\"history\",  # (이전)기록 메시지의 키\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableWithMessageHistory 설정 매개변수\n",
    "\n",
    "- runnable\n",
    "\n",
    "- BaseChatMessageHistory 이거나 상속받은 객체. ex) ChatMessageHistory\n",
    "\n",
    "- input_messages_key: chain 을 invoke() 할때 사용자 쿼리 입력으로 지정하는 key\n",
    "\n",
    "- history_messages_key: 대화 기록으로 지정하는 key"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "if history_factory_config:\n",
    "    _config_specs = history_factory_config\n",
    "else:\n",
    "    # If not provided, then we'll use the default session_id field\n",
    "    _config_specs = [\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for a session.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드를 보면 RunnableWithMessageHistory 의 초기값에 session_id 키를 Default 로 삽입하는 것을 볼 수 있으며, \n",
    "\n",
    "이 코드로 인하여 RunnableWithMessageHistory 는 대화 스레드 관리를 session_id 로 한다는 것을 간접적으로 알 수 있습니다.\n",
    "\n",
    "즉, 대화 스레드별 관리는 session_id 별로 구현함을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Trigonometric function that gives the ratio of the adjacent side to the hypotenuse in a right triangle.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 47, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b9d5b261-6236-4541-ae4b-dafc325a72a6-0', usage_metadata={'input_tokens': 47, 'output_tokens': 22, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    # 설정 정보로 세션 ID \"abc123\"을 전달합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 session_id 를 입력하면 이전 대화 스레드의 내용을 가져오기 때문에 이어서 대화가 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인접 변의 길이와 빗변의 길이의 비율을 나타내는 삼각함수입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 161, 'total_tokens': 198, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7b1c677d-0c27-4697-9d46-b610f8064c14-0', usage_metadata={'input_tokens': 161, 'output_tokens': 37, 'total_tokens': 198, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메시지 기록을 포함하여 호출합니다.\n",
    "with_message_history.invoke(\n",
    "    # 능력과 입력을 설정합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"이전의 내용을 한글로 답변해 주세요.\"},\n",
    "    # 설정 옵션을 지정합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 다른 session_id 를 지정하면 대화기록이 없기 때문에 답변을 제대로 수행하지 못합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='수학에 능숙한 어시스턴트입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 58, 'total_tokens': 77, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0168962f-994a-4140-99ff-41e1a17e76fa-0', usage_metadata={'input_tokens': 58, 'output_tokens': 19, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 session_id로 인해 이전 대화 내용을 기억하지 않습니다.\n",
    "with_message_history.invoke(\n",
    "    # 수학 능력과 입력 메시지를 전달합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"이전의 내용을 한글로 답변해 주세요\"},\n",
    "    # 새로운 session_id를 설정합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"def234\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메시지 기록을 추적하는 데 사용되는 구성 매개변수는 ConfigurableFieldSpec 객체의 리스트를 history_factory_config 매개변수로 전달하여 사용자 정의할 수 있습니다.\n",
    "\n",
    "이렇게 history_factory_config 를 새로 설정하게 되면 기존 session_id 설정을 덮어쓰게 됩니다.\n",
    "\n",
    "아래 예시에서는 user_id와 conversation_id라는 두 가지 매개변수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "store = {}  # 빈 딕셔너리를 초기화합니다.\n",
    "\n",
    "\n",
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    # 주어진 user_id와 conversation_id에 해당하는 세션 기록을 반환합니다.\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        # 해당 키가 store에 없으면 새로운 ChatMessageHistory를 생성하여 저장합니다.\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "    return store[(user_id, conversation_id)]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[  # 기존의 \"session_id\" 설정을 대체하게 됩니다.\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",  # get_session_history 함수의 첫 번째 인자로 사용됩니다.\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"사용자의 고유 식별자입니다.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",  # get_session_history 함수의 두 번째 인자로 사용됩니다.\n",
    "            annotation=str,\n",
    "            name=\"Conversation ID\",\n",
    "            description=\"대화의 고유 식별자입니다.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 43, 'total_tokens': 64, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-414f13d1-037c-4e54-97aa-9ac2f1d92b1b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 21, 'total_tokens': 64, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    # 능력(ability)과 입력(input)을 포함한 딕셔너리를 전달합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"Hello\"},\n",
    "    # 설정(config) 딕셔너리를 전달합니다.\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 답변은 이전 대화기록이 없으므로, 제대로 된 답변을 받을 수 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영구 저장소 활용 : RedisChatMessageHistory 사용하기 _docker 설치 진행중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redis를 사용하는 방법은 메시지 기록을 영구적으로 저장할 수 있게 해줍니다. \n",
    "\n",
    "Redis는 높은 성능을 제공하는 오픈 소스 인메모리 데이터 구조 저장소로, 분산 환경에서도 안정적으로 메시지 기록을 관리할 수 있습니다. \n",
    "\n",
    "이 방법은 복잡한 애플리케이션 또는 장기간 운영되는 서비스에 적합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redis 설치"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "pip install -qU redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docker 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://urame.tistory.com/entry/window-docker-%EB%AC%B4%EB%A3%8C-%EC%84%A4%EC%B9%98-feat-WSL-%ED%99%9C%EC%9A%A9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "docker --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redis 서버 구동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존에 연결할 Redis 배포가 없는 경우, 로컬 Redis Stack 서버를 시작합니다.\n",
    "\n",
    "다음은 Docker 로 Redis 서버를 구동하는 명령어입니다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REDIS_URL 변수에 Redis 데이터베이스의 연결 URL을 할당합니다.\n",
    "\n",
    "URL은 \"redis://localhost:6379/0\"로 설정되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis 서버의 URL을 지정합니다.\n",
    "REDIS_URL = \"redis://localhost:6379/0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메시지 기록 구현을 업데이트하려면 새로운 호출 가능한 객체를 정의하고, 이번에는 RedisChatMessageHistory의 인스턴스를 반환하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RedisChatMessageHistory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
    "\n",
    "\n",
    "def get_message_history(session_id: str) -> RedisChatMessageHistory:\n",
    "    # 세션 ID를 기반으로 RedisChatMessageHistory 객체를 반환합니다.\n",
    "    return RedisChatMessageHistory(session_id, url=REDIS_URL)\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,  # 실행 가능한 객체\n",
    "    get_message_history,  # 메시지 기록을 가져오는 함수\n",
    "    input_messages_key=\"input\",  # 입력 메시지의 키\n",
    "    history_messages_key=\"history\",  # 기록 메시지의 키\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전과 동일한 방식으로 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "    # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    # 설정 옵션으로 세션 ID를 \"redis123\" 로 지정합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"redis123\"}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 session_id를 사용하여 두 번째 호출을 수행합니다. 이번에는 이전의 답변을 한글로 답변해 달라는 요청을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "    # 이전 답변에 대한 한글 번역을 요청합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"이전의 답변을 한글로 번역해 주세요.\"},\n",
    "    # 설정 값으로 세션 ID를 \"foobar\"로 지정합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"redis123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 다른 session_id를 사용하여 질문을 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "    # 이전 답변에 대한 한글 번역을 요청합니다.\n",
    "    {\"ability\": \"math\", \"input\": \"이전의 답변을 한글로 번역해 주세요.\"},\n",
    "    # 설정 값으로 세션 ID를 \"redis456\"로 지정합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"redis456\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 답변은 이전 대화기록이 없으므로, 제대로 된 답변을 받을 수 없습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
