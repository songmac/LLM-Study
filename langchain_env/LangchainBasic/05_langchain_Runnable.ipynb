{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith API Key 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langsmith로 프로젝트 추적 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "Runnable\n"
     ]
    }
   ],
   "source": [
    "from utils import logging\n",
    "\n",
    "logging.langsmith(\"Runnable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용자 정의 체인을 쉽게 만들 수 있는 프로토콜이며, 데이터를 효과적으로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='50입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7ca5ab83-69ac-44c5-a1ac-0a4417208751-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"num\": 5}) # 기본\n",
    "chain.invoke(5) # 1개의 변수만 있을 때 이렇게도 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable 객체를 사용한 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{num} 의 10배는?\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | llm\n",
    "runnable_chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 방식은 딕셔너리 형태로 입력값을 전달해야 하며, 단순하게 특정 변수에 값을 바로 치환하는 방식입니다.\n",
    "\n",
    "Runnable 객체를 이용한 방식은 입력값을 가공하거나 유연하게 처리할 수 있는 구조를 제공합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnablePassthrough 는 입력을 변경하지 않거나 추가 키를 더하여 전달할 수 있습니다.\n",
    "\n",
    "- RunnablePassthrough() 가 단독으로 호출되면, 단순히 입력을 받아 그대로 전달합니다.\n",
    "\n",
    "- RunnablePassthrough.assign(...) 방식으로 호출되면, 입력을 받아 assign 함수에 전달된 추가 인수를 추가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# runnable\n",
    "RunnablePassthrough().invoke({\"num\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='100입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 16, 'total_tokens': 19, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-650d0135-d18d-45a1-807e-043ec79d977c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 3, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | llm\n",
    "runnable_chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnablePassthrough.assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 값으로 들어온 값의 key/value 쌍과 새롭게 할당된 key/value 쌍을 합칩니다.\n",
    "# 입력 키 : num, 할당(assign) 키 : new_num\n",
    "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableParallel 인스턴스를 생성합니다.\n",
    "\n",
    "이 인스턴스는 여러 Runnable 인스턴스를 병렬로 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Runnableparallel 인스턴스 생성\n",
    "runnable = RunnableParallel(\n",
    "    passed = RunnablePassthrough(),\n",
    "    extra = RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    modified = lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "# runnable 인스턴스에 {\"num\": 1} 딕셔너리를 입력으로 전달하여 invoke 메소드를 호출\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain 도 RunnableParallel 적용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} 의 수도는?\")\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "chain2 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"{country} 의 면적은?\")\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "\n",
    "combined_chain = RunnableParallel(capital=chain1, area=chain2)\n",
    "combined_chain.invoke(\"대한민국\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableLambda 는 사용자 정의 함수를 실행 할 수 있는 기능을 제공합니다.\n",
    "\n",
    "이를 통해 개발자는 자신만의 함수를 정의하고, 해당 함수를 RunnableLambda 를 사용하여 실행할 수 있습니다.\n",
    "\n",
    "예를 들어, 데이터 전처리, 계산, 또는 외부 API와의 상호 작용과 같은 작업을 수행하는 함수를 정의하고 실행할 수 있습니다.\n",
    "\n",
    "\n",
    "#### 주의사항\n",
    "\n",
    "사용자 정의 함수를 RunnableLambda로 래핑하여 활용할 수 있는데, 여기서 주의할 점은 사용자 정의 함수가 받을 수 있는 인자는 1개 뿐이라는 점 입니다.\n",
    "\n",
    "만약, 여러 인수를 받는 함수로 구현하고 싶다면, 단일 입력을 받아들이고 이를 여러 인수로 풀어내는 래퍼를 작성해야 합니다.\n",
    "\n",
    "wrapper란?\n",
    "- 래퍼(wrapper) 함수란, 다른 함수를 감싸서 호출하거나 그 함수의 동작을 확장, 변형, 또는 단순화하는 역할을 하는 함수입니다. \n",
    "래퍼 함수는 기존의 함수 호출 전에 추가적인 작업을 수행하거나, 함수의 결과를 처리하는 작업을 추가하고자 할 때 유용하게 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter \n",
    "# operator.itemgetter는 주로 sorted와 같은 함수의 key 매개변수에 적용하여 다양한 기준으로 정렬할 수 있도록 하는 모듈\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def length_function(text):  # 텍스트의 길이를 반환하는 함수\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):  # 두 텍스트의 길이를 곱하는 함수\n",
    "    \"\"\"이름 앞에 _가 붙어 있으므로 내부용(private) 함수로 설계된 것\"\"\"\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(  # 2개의 딕셔너리 인자를 받는 함수로 연결하는 wrapper 함수\n",
    "    _dict,\n",
    "):  # 딕셔너리에서 \"text1\"과 \"text2\"의 길이를 곱하는 함수\n",
    "    \"\"\" \n",
    "    하나의 딕셔너리 _dict를 인자로 받고, \n",
    "    그 딕셔너리 내에서 text1과 text2라는 두 개의 키에 해당하는 값들을 추출해\n",
    "    _multiple_length_function 함수에 전달\n",
    "    \"\"\"\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}?\")\n",
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 프롬프트와 모델을 연결하여 체인 생성\n",
    "chain1 = prompt | model\n",
    "\n",
    "# 체인 구성\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"input_1\") | RunnableLambda(length_function), # 3\n",
    "        \"b\": {\"text1\": itemgetter(\"input_1\"), \"text2\": itemgetter(\"input_2\")} | RunnableLambda(multiple_length_function), # 9\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 + 9 = 12'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 인자들로 체인을 실행합니다.\n",
    "chain.invoke({\"input_1\": \"bar\", \"input_2\": \"gah\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @chain 데코레이터를 사용해 Runnable 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@chain 데코레이터를 추가하여 임의의 함수를 체인으로 변환할 수 있습니다.\n",
    "\n",
    "이는 함수를 RunnableLambda로 래핑하는 것과 기능적으로 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatPromptTemplate 클래스를 사용하여 두 개의 프롬프트 템플릿을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿을 정의합니다.\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{topic} 에 대해 짧게 한글로 설명해주세요.\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{sentence} 를 emoji를 활용한 인스타그램 게시글로 만들어주세요.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_chain 함수는 입력 텍스트를 기반으로 사용자 정의 체인을 실행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@chain 데코레이터로 사용자 정의 함수를 데코레이팅 하며, 데코레이팅을 통해 함수를 Runnable 한 객체로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def custom_chain(text):\n",
    "    # 첫 번째 프롬프트, ChatOpenAI, 문자열 출력 파서를 연결하여 체인을 생성합니다.\n",
    "    chain1 = prompt1 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "    output1 = chain1.invoke({\"topic\": text})\n",
    "\n",
    "    # 두 번째 프롬프트, ChatOpenAI, 문자열 출력 파서를 연결하여 체인을 생성합니다.\n",
    "    chain2 = prompt2 | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "    # 두 번째 체인을 호출하여 파싱된 첫 번째 결과를 전달하고 최종 결과를 반환합니다.\n",
    "    return chain2.invoke({\"sentence\": output1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_chain은 이제 실행 가능한 객체(runnable)이므로, invoke() 를 사용하여 실행해야 합니다.\n",
    "\n",
    "LangSmith 추적 기록을 확인해 보면, custom_chain 추적 정보가 있을 것이며, 그 아래에는 OpenAI 호출이 중첩되어 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌌✨ 양자역학의 매력에 빠져보세요! 🔍💫\n",
      "\n",
      "양자역학은 물리학의 한 분야로, 원자와 아원자 입자의 신비한 행동을 설명합니다. 🧬💥 고전 물리학과는 달리, 양자역학은 입자가 특정한 위치에 동시에 존재할 수 없고, 확률적인 성질을 가진다고 해요! 🎲🔮\n",
      "\n",
      "입자의 상태는 관측하기 전까지 확정되지 않으며, 이는 '파동-입자 이중성'과 '불확정성 원리'로 유명하답니다. 🌊➡️⚛️✨ 현대 물리학의 기초를 이루며, 반도체, 레이저, 양자 컴퓨팅 등 다양한 기술의 발전에 기여하고 있어요! 💻⚡️\n",
      "\n",
      "양자세계의 신비로움을 함께 탐험해봐요! 🌟🔭 #양자역학 #물리학 #과학의세계 #혁신 #기술발전 #파동입자이중성 #불확정성원리\n"
     ]
    }
   ],
   "source": [
    "# custom_chain을 호출\n",
    "print(custom_chain.invoke(\"양자역학\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
